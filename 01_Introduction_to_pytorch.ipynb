{"cells":[{"metadata":{},"cell_type":"markdown","source":"> "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport torch ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tensors\nTorch use tensors to represent data in a very efficent way, you can perfom several mathematical operations efficiently and fast"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we create some random input data\ninputs=torch.randn(1,5)\nprint(inputs,\"\\n\",inputs.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can build neural networks perfoming the corresponding mathematical operations between tensors for example let's say we want to create a single layer network with 3 hidden units (neurons) and 4 inputs so\nin this case our inputs X should be multiplied by the weight matrix W of the layer \n$$\n\\begin{equation*}\n{X} \\times {W}= \\begin{bmatrix}\n\\mathbf{x}_1 & \\mathbf{x}_2 & \\mathbf{x}_3 & \\mathbf{x}_4\\\\\n\\end{bmatrix}\n\\times\n\\begin{vmatrix}\n\\mathbf{h}_1 & \\mathbf{h}_2 & \\mathbf{h}_3 \\\\\n{w}_{11}&{w}_{21}&{w}_{31}\\\\\n{w}_{12}&{w}_{22}&{w}_{32}\\\\\n{w}_{13}&{w}_{23}&{w}_{33}\\\\\n{w}_{14}&{w}_{24}&{w}_{34}\n\\end{vmatrix}\n\\end{equation*}\n$$\nWhere each column of W represent the 4 weights of a hidden unit $$h_{1-3}$$ corresponding to each input $$x_{1-4}$$ \n\nW will have as many columns as neurons and as many rows as inputs,we are performing the dot product of each column and the inputs to get a score for each neuron,those scores will be stored in a hidden vector h\n\nthen we will sum the bias to the hidden state vector h = X * W \n$$\n\\begin{bmatrix}\n\\mathbf{h}_1 & \\mathbf{h}_2 & \\mathbf{h}_3 \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\mathbf{b}_1 & \\mathbf{b}_2 & \\mathbf{b}_3 \\\\\n\\end{bmatrix}\n$$\nat the end our network will be \n$$\n\\mathbf{Y}_{prediction}=W\\times X + b\n$$\n\n"},{"metadata":{},"cell_type":"markdown","source":"Implementing the basic dense layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def no_activation(x):\n    return x","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+torch.exp(x))","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass dense():\n    def __init__(self,input_d,units):\n        self.weights=torch.randn((input_d,units))\n        self.bias=torch.randn((1,units))\n    def __call__(self,inputs,activation=no_activation):\n        return activation(torch.mm(inputs,self.weights)+self.bias)","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a simple model using 1 hidden layer with two neurons and and output layer with one neuron "},{"metadata":{"trusted":true},"cell_type":"code","source":"class model():\n    def __init__(self,input_d):\n        self.layer1=dense(input_d,2)\n        self.layer2=dense(self.layer1.weights.shape[1],1)\n    def __call__(self,inputs):\n        h1= self.layer1(inputs,activation=sigmoid)\n        h2= self.layer2(h1,activation=sigmoid)\n        return h2","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntorch.manual_seed(7)\nfeatures = torch.randn((1, 3))\nfirstnet=model(features.shape[1])\nfirstnet(features)","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"tensor([[0.3988]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"we can create tensors from numpy arrays "},{"metadata":{"trusted":true},"cell_type":"code","source":"a=np.random.rand(4,3)\na","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"array([[0.56769186, 0.22367925, 0.89483703],\n       [0.10305367, 0.85194735, 0.76680896],\n       [0.46295481, 0.25728581, 0.02462051],\n       [0.52885316, 0.67472357, 0.85574091]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"in this case the new tensor will share mamoery whit the numpy array so wherever change we made in any of them will affect each other"},{"metadata":{"trusted":true},"cell_type":"code","source":"b=torch.from_numpy(a)\nb","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"tensor([[0.5677, 0.2237, 0.8948],\n        [0.1031, 0.8519, 0.7668],\n        [0.4630, 0.2573, 0.0246],\n        [0.5289, 0.6747, 0.8557]], dtype=torch.float64)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"b.mul_(2)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"tensor([[1.1354, 0.4474, 1.7897],\n        [0.2061, 1.7039, 1.5336],\n        [0.9259, 0.5146, 0.0492],\n        [1.0577, 1.3494, 1.7115]], dtype=torch.float64)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"a","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([[1.13538372, 0.4473585 , 1.78967407],\n       [0.20610733, 1.7038947 , 1.53361792],\n       [0.92590962, 0.51457161, 0.04924101],\n       [1.05770631, 1.34944714, 1.71148182]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We can also create new tensor from numpy arrays without sharing memory between them, so this new tensor will have its own memory, and the changes on it will not affect the numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"b_nosharedmemory = torch.Tensor(a)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b_nosharedmemory","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"tensor([[1.1354, 0.4474, 1.7897],\n        [0.2061, 1.7039, 1.5336],\n        [0.9259, 0.5146, 0.0492],\n        [1.0577, 1.3494, 1.7115]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"b_nosharedmemory.mul_(2)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"tensor([[2.2708, 0.8947, 3.5793],\n        [0.4122, 3.4078, 3.0672],\n        [1.8518, 1.0291, 0.0985],\n        [2.1154, 2.6989, 3.4230]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"a","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"array([[1.13538372, 0.4473585 , 1.78967407],\n       [0.20610733, 1.7038947 , 1.53361792],\n       [0.92590962, 0.51457161, 0.04924101],\n       [1.05770631, 1.34944714, 1.71148182]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"b_nosharedmemory","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"tensor([[2.2708, 0.8947, 3.5793],\n        [0.4122, 3.4078, 3.0672],\n        [1.8518, 1.0291, 0.0985],\n        [2.1154, 2.6989, 3.4230]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Lets create a neural net two solve the mnist from of predict the number appearing on an image"},{"metadata":{},"cell_type":"markdown","source":"We defined a transform to normalize the data , we are going to tranform each image to a vectorand also normalize it in a range of [-1,1] (standart normal distribution) image = (image - mean) / std the function normalize recieves two parameters mean and std in our case mean=0.5 and std=0.5 this normalization provides a better workfield to gradient descent since in the end we want to capture the distribution of the data its easier to capture a normal distribution 0 mean and equal variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import datasets,transforms\n\n\n\ntransform = transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5,), (0.5,)),\n                              ])\n# Download and load the data\ndata= datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n","execution_count":33,"outputs":[{"output_type":"stream","text":"  0%|          | 16384/9912422 [00:00<01:33, 105744.40it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"9920512it [00:00, 23983954.74it/s]                           \n","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"32768it [00:00, 330719.97it/s]\n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\nExtracting /tmp/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"1654784it [00:00, 5339853.75it/s]                           \n8192it [00:00, 72582.92it/s]            \n","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting /tmp/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this dataloader will split the data in batches of 64 samples and will shuffle them \ndataloader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nAs we can see the data loader iterates giving us a batch of 64  images  each time"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(dataloader)\nimages, labels = dataiter.next()\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)","execution_count":35,"outputs":[{"output_type":"stream","text":"<class 'torch.Tensor'>\ntorch.Size([64, 1, 28, 28])\ntorch.Size([64])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');","execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADnZJREFUeJzt3X+MVfWZx/HPIwU1tAlgA0xAhEVdtzE61AmalBjWhobdkGCjNZgY2bgpNemEbbImGv8QjWlS14VdUVJDUyxNwLYBf5DabCFmFTBiHHBTodBiYIRZyEwNNVCjIcKzf8xhM8W53zNzzzn33OF5vxIy997nnnue3OEz59z7/d77NXcXgHguq7sBAPUg/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvpSK3dmZkwnBCrm7jaS+xU68pvZYjP7g5l9YGaPFHksAK1lzc7tN7Nxkv4oaZGkPknvSrrX3X+f2IYjP1CxVhz550v6wN2PuPtZSb+QtLTA4wFooSLhnyHp+JDrfdltf8XMVphZj5n1FNgXgJIVecNvuFOLL5zWu/t6SeslTvuBdlLkyN8n6eoh12dKOlGsHQCtUiT870q6zszmmNkEScskbSunLQBVa/q0390/N7NuSb+VNE7SBnc/UFpnACrV9FBfUzvjNT9QuZZM8gEwdhF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRLl+iOauLEicn6rl27kvV58+Yl60eOHGlYmzt3bnJbxMWRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCKjTOb2a9ks5IOifpc3fvKqOpS83DDz+crN98883Jet5KytOnT29Ye+utt5Lb1mnt2rXJ+ttvv52sHzt2rMx2wiljks/fu/tHJTwOgBbitB8Iqmj4XdJ2M9trZivKaAhAaxQ97f+Gu58ws6mSdpjZIXffOfQO2R8F/jAAbabQkd/dT2Q/ByS9LGn+MPdZ7+5dvBkItJemw29mE83sKxcuS/qWpP1lNQagWkVO+6dJetnMLjzOZnf/r1K6AlA5yxtDLnVnZq3bWQvdeuutyfobb7yRrE+YMCFZz/7ANlTl77DOfff39yfrK1euTNa3bNlSZjtjhrunf2kZhvqAoAg/EBThB4Ii/EBQhB8IivADQTHUV4LFixcn66+99lqhx88bbtu3b1/D2qFDhyrd98yZM5P1BQsWVLbv1FeWS9K1117b9L7HMob6ACQRfiAowg8ERfiBoAg/EBThB4Ii/EBQLNFdgkWLFiXreePVee64445kPe8jw+0qr+/bb789Wb/mmmua3n7nzp0Na1Fw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnL8Ftt92WrBf9zoSxOo6fZ+rUqYW2//DDD5N1xvLTOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFC54/xmtkHSEkkD7n5jdtsUSb+UNFtSr6R73P3P1bUZW3d3d7L+3HPPtaiT0ZszZ07DWt7n8fMcPXq00PbRjeTI/zNJF69K8Yik1939OkmvZ9cBjCG54Xf3nZJOXXTzUkkbs8sbJd1Zcl8AKtbsa/5p7n5SkrKfxeZpAmi5yuf2m9kKSSuq3g+A0Wn2yN9vZh2SlP0caHRHd1/v7l3u3tXkvgBUoNnwb5O0PLu8XNKr5bQDoFVyw29mL0p6W9Lfmlmfmf2zpB9JWmRmhyUtyq4DGENyX/O7+70NSt8suZcxa+3atcl63uf989x///3Jeur7AtatW1do33lzCO67775kffz48Q1rV1xxRXLbs2fPJuurVq1K1pHGDD8gKMIPBEX4gaAIPxAU4QeCIvxAUHx1dwn6+/uT9c8++yxZv/LKK5P1rq705MhU/dlnn01u285eeOGFZJ2P9BbDkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgrKiy0ePamdmrdtZG5k9e3ayfuDAgWQ9bx5Alb9DM2vbfX/66afJ+qZNmxrWnn766eS2hw8fTtbbmbunn7gMR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/hZILVMtSfv370/Wqxznf++995L1vO8imDx5crJ+ww03jLqnC6qcY/DJJ58k61u3bk3Wn3jiiWS9t7d3tC2VhnF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU7ji/mW2QtETSgLvfmN32uKTvSvpTdrdH3f03uTu7RMf5Z82alazv2bMnWZ82bVqyXmS8+/nnn09uu3LlymT93LlzyXreMtvTp09P1lMmTZqUrD/00EPJemqOwbx585Lb5j3neXMzbrrppmS9SmWO8/9M0uJhbv8Pd+/M/uUGH0B7yQ2/u++UdKoFvQBooSKv+bvN7HdmtsHM0nM8AbSdZsP/Y0lzJXVKOilpdaM7mtkKM+sxs54m9wWgAk2F39373f2cu5+X9BNJ8xP3Xe/uXe6eXm0SQEs1FX4z6xhy9duS0m99Amg7uUt0m9mLkhZK+qqZ9UlaJWmhmXVKckm9kr5XYY8AKsDn+UuwbNmyZH3z5s2FHv+pp55K1vv6+hrW1q1bV2jfl6pt27Yl60uWLCn0+GvWrEnW8+YoFMHn+QEkEX4gKMIPBEX4gaAIPxAU4QeCYqhvhFIfXd27d29y2yJfXy1J48aNK7Q9Ru/06dPJ+sSJE5P1Q4cOJeu33HJLw1re16XnYagPQBLhB4Ii/EBQhB8IivADQRF+ICjCDwSV+3l+DOro6GhYKzqOv3v37kLbo3yHDx9O1js7O5P1vPkz58+fH3VPZePIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc7fBubPb7jgESqycOHCZD1vCe+8cfyPP/44WT979myy3goc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqNxxfjO7WtLPJU2XdF7Send/xsymSPqlpNmSeiXd4+5/rq7Veh09erRh7cknn0xu+9hjjyXrl19+ebKe9z3uzzzzTMPa6tWrk9sODAwk65equ+++u9D2Zumvxt++fXuhx2+FkRz5P5f0r+7+d5Juk/R9M/uapEckve7u10l6PbsOYIzIDb+7n3T3fdnlM5IOSpohaamkjdndNkq6s6omAZRvVK/5zWy2pHmS3pE0zd1PSoN/ICRNLbs5ANUZ8dx+M/uypK2SfuDup/Ne8wzZboWkFc21B6AqIzrym9l4DQZ/k7u/lN3cb2YdWb1D0rDvHLn7enfvcveuMhoGUI7c8NvgIf6nkg66+5ohpW2SlmeXl0t6tfz2AFQld4luM1sgaZek9zU41CdJj2rwdf+vJM2SdEzSd9z9VM5jjdklulOmTk2/3fHmm28m69dff32ynvcSK/U7PHPmTHLbAwcOJOs7duxI1vfs2ZOsP/DAAw1rM2bMSG5bpa6u9InoZZelj4s9PT3J+tKlS5P1KodYR7pEd+5rfnffLanRg31zNE0BaB/M8AOCIvxAUIQfCIrwA0ERfiAowg8ElTvOX+rOLtFx/jx58wAefPDBZL27uztZv+qqq0bd00gVmWMwlvedNz9i0qRJle27qJGO83PkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOcfA6ZMmZKsd3Z2NqylPk8vSXfddVeynve14u08zr979+6GtS1btiS3feWVV5L148ePJ+t1YpwfQBLhB4Ii/EBQhB8IivADQRF+ICjCDwTFOD9wiWGcH0AS4QeCIvxAUIQfCIrwA0ERfiAowg8ElRt+M7vazP7bzA6a2QEz+5fs9sfN7H/N7H+yf/9YfbsAypI7ycfMOiR1uPs+M/uKpL2S7pR0j6S/uPu/j3hnTPIBKjfSST5fGsEDnZR0Mrt8xswOSppRrD0AdRvVa34zmy1pnqR3spu6zex3ZrbBzCY32GaFmfWYWU+hTgGUasRz+83sy5LelPRDd3/JzKZJ+kiSS3pSgy8Nkl8Yx2k/UL2RnvaPKPxmNl7SryX91t3XDFOfLenX7n5jzuMQfqBipX2wxwa/QvWnkg4ODX72RuAF35a0f7RNAqjPSN7tXyBpl6T3JZ3Pbn5U0r2SOjV42t8r6XvZm4Opx+LID1Ss1NP+shB+oHp8nh9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3C/wLNlHkj4ccv2r2W3tqF17a9e+JHprVpm9XTPSO7b08/xf2LlZj7t31dZAQrv21q59SfTWrLp647QfCIrwA0HVHf71Ne8/pV17a9e+JHprVi291fqaH0B96j7yA6hJLeE3s8Vm9gcz+8DMHqmjh0bMrNfM3s9WHq51ibFsGbQBM9s/5LYpZrbDzA5nP4ddJq2m3tpi5ebEytK1PnfttuJ1y0/7zWycpD9KWiSpT9K7ku5199+3tJEGzKxXUpe71z4mbGa3S/qLpJ9fWA3JzP5N0il3/1H2h3Oyuz/cJr09rlGu3FxRb41Wlv4n1fjclbnidRnqOPLPl/SBux9x97OSfiFpaQ19tD133ynp1EU3L5W0Mbu8UYP/eVquQW9twd1Puvu+7PIZSRdWlq71uUv0VYs6wj9D0vEh1/vUXkt+u6TtZrbXzFbU3cwwpl1YGSn7ObXmfi6Wu3JzK120snTbPHfNrHhdtjrCP9xqIu005PANd/+6pH+Q9P3s9BYj82NJczW4jNtJSavrbCZbWXqrpB+4++k6exlqmL5qed7qCH+fpKuHXJ8p6UQNfQzL3U9kPwckvazBlyntpP/CIqnZz4Ga+/l/7t7v7ufc/bykn6jG5y5bWXqrpE3u/lJ2c+3P3XB91fW81RH+dyVdZ2ZzzGyCpGWSttXQxxeY2cTsjRiZ2URJ31L7rT68TdLy7PJySa/W2MtfaZeVmxutLK2an7t2W/G6lkk+2VDGf0oaJ2mDu/+w5U0Mw8z+RoNHe2nwE4+b6+zNzF6UtFCDn/rql7RK0iuSfiVplqRjkr7j7i1/461Bbws1ypWbK+qt0crS76jG567MFa9L6YcZfkBMzPADgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDU/wEd+HZmFLeFpgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"[](http://)"},{"metadata":{},"cell_type":"markdown","source":"we will apply exp to all the elements in our data, then we know each row of our data is a prediction, so we should sum by rows (in dim=1) and also in order to divide 10 values by 10 values we should transpose that summaroty of the rows two divide the the row by a value "},{"metadata":{"trusted":true},"cell_type":"code","source":"def softmax(x):\n    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class model(object):\n    def __init__(self,input_d):\n        self.layer1=dense(input_d,256)\n        self.outputlayer=dense(self.layer1.weights.shape[1],10)\n    def __call__(self,inputs):\n        h1=self.layer1(inputs,activation=sigmoid)\n        out=self.outputlayer(h1,activation=softmax)\n        return out","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = images.view(images.shape[0], -1)\ninputs.shape","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"torch.Size([64, 784])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_net=model(inputs.shape[1])\noutputs=mnist_net(inputs)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(outputs.shape)\nprint(torch.sum(outputs,dim=1))","execution_count":41,"outputs":[{"output_type":"stream","text":"torch.Size([64, 10])\ntensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Using the nn module to create models"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nclass model(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=nn.Linear(784,256)\n        self.out_Layer=nn.Linear(256,10)\n    def __call__(self,inputs):\n        h1=torch.sigmoid(self.layer1(inputs))\n        out=torch.softmax(self.out_Layer(h1),dim=1) #we will calculate the softamx by row \n        return out\n    ","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torchmodel=model(inputs.shape[1])\ntorchmodel","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"model(\n  (layer1): Linear(in_features=784, out_features=256, bias=True)\n  (out_Layer): Linear(in_features=256, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs=torchmodel(inputs)\noutputs.shape","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"torch.Size([64, 10])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.sum(outputs,dim=1)","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000], grad_fn=<SumBackward2>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Lets build a more complex architecture also using other activation functions such as ReLU"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nclass Model(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=nn.Linear(input_d,128)\n        self.layer2=nn.Linear(self.layer1.out_features,64)\n        self.out_layer=nn.Linear(self.layer2.out_features,10)\n    def __call__(self,inputs):\n        h1=F.relu(self.layer1(inputs))\n        h2=F.relu(self.layer2(h1))\n        out=torch.softmax(self.out_layer(h2),dim=1)\n        return out\n        \n        \n    ","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relumodel=Model(inputs.shape[1])\nrelumodel","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"Model(\n  (layer1): Linear(in_features=784, out_features=128, bias=True)\n  (layer2): Linear(in_features=128, out_features=64, bias=True)\n  (out_layer): Linear(in_features=64, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.sum(relumodel(inputs),dim=1)\n","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000], grad_fn=<SumBackward2>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's build a model and calculate the loss noticed that we calculate the loss with the output scores and not whit the probabilities coming from the activation function (softmax)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(784, 128),\n                      nn.ReLU(),\n                      nn.Linear(128, 64),\n                      nn.ReLU(),\n                      nn.Linear(64, 10))\n\n# Define the loss\ncriterion = nn.CrossEntropyLoss()\n\n# Get our data\nimages, labels = next(iter(dataloader))\n# Flatten images\nimages = images.view(images.shape[0], -1)\n\n# Forward pass, get our logits\nlogits = model(images)\n# Calculate the loss with the logits and the labels\nloss = criterion(logits, labels)\n\nprint(loss)","execution_count":49,"outputs":[{"output_type":"stream","text":"tensor(2.3237, grad_fn=<NllLossBackward>)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":" it's more convenient to build the model with a log-softmax output ,then you can get the actual probabilities by taking the exponential torch.exp(output). With a log-softmax output, we should use  to use the negative log likelihood loss\n \n \nThe softmax function returns probabilities between [0, 1].\nThe log of these probabilities returns values between [-inf, 0], since log(0) = -inf and log(1) = 0.\nThat is why the order won’t change.\n\nHowever, you should use the NLLLoss with a log_softmax output\nor CrossEntropyLoss with logits if you prefer not to add an extra log_softmax layer into your model."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# TODO: Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(images.shape[1],250),\n                      nn.ReLU(),\n                      nn.Linear(250,120),\n                      nn.ReLU(),\n                      nn.Linear(120,10),\n                      nn.LogSoftmax(dim=1) \n                      #because we want to softmax by row (each row contains the score of a input), \n                      #we have 64 rows because our batch is of 64 samples\n                      )\n\n# TODO: Define the loss\ncriterion = nn.NLLLoss()\n\n\n# Forward pass, get our logits\nlogits = model(images)\nprint(logits.shape)\nprint(torch.sum(torch.exp(logits),dim=1))\n# Calculate the loss with the logits and the labels\nloss = criterion(logits, labels)\n\nprint(loss)","execution_count":50,"outputs":[{"output_type":"stream","text":"torch.Size([64, 10])\ntensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000], grad_fn=<SumBackward2>)\ntensor(2.2840, grad_fn=<NllLossBackward>)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"![](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"images.shape","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"torch.Size([64, 784])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Autograd\n\nAutograd allow us to track the operations done on a tensor and when you tell it to do a backward pass , it will go backwards  trought  each of these operations and calculate the gradients whit resect to the input parameters "},{"metadata":{},"cell_type":"markdown","source":"In torch you need to indicate that you require to calculate the gradients of a tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor=torch.randn(2,2,requires_grad=True)\ntensor","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"tensor([[-0.6817,  0.7923],\n        [ 0.3231, -0.9885]], requires_grad=True)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"You also can turn the grads of and turn in on again on a tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor.requires_grad=False\nprint(\"grads off:\\n\",tensor)\ntensor.requires_grad=True\nprint(\"grads on:\\n\",tensor)","execution_count":53,"outputs":[{"output_type":"stream","text":"grads off:\n tensor([[-0.6817,  0.7923],\n        [ 0.3231, -0.9885]])\ngrads on:\n tensor([[-0.6817,  0.7923],\n        [ 0.3231, -0.9885]], requires_grad=True)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"you can also use contexts to control the grads tracking"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y=tensor**2\ny.requires_grad","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"False"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tensor)\nwith torch.no_grad():\n    tensor=tensor**2\nprint(tensor)\ntensor.requires_grad=True","execution_count":55,"outputs":[{"output_type":"stream","text":"tensor([[-0.6817,  0.7923],\n        [ 0.3231, -0.9885]], requires_grad=True)\ntensor([[0.4647, 0.6278],\n        [0.1044, 0.9771]])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"in this case we see the torch wil track the operations in the tensor since we stablish requieres_grad as True\nwe can also globally enable or disable grads globally using \n```python\ntorch.set_grad_enabled(True|false)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor=torch.sqrt(tensor)\ntensor","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"tensor([[0.6817, 0.7923],\n        [0.3231, 0.9885]], grad_fn=<SqrtBackward>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"then let's say we have a function \n$$\ny=x^2\n$$\n\nand also\n$$\nz = \\left[\\frac{1}{n}\\sum_i^n y_i\\right]\n$$\n\nso then we want to calculate the gradients of z with respect x\n\n$$\n\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n$$\n\nwe can easily perfom this with autograd in pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=torch.randn(2,2,requires_grad=True)\nprint(f\"x: \\n{x}\")\ny=x**2\nprint(f\"y: \\n{y}\")\nz=torch.mean(y)\nprint(f\"z: \\n{z}\")\n","execution_count":57,"outputs":[{"output_type":"stream","text":"x: \ntensor([[-1.3821,  0.4229],\n        [ 1.0354,  2.4317]], requires_grad=True)\ny: \ntensor([[1.9102, 0.1789],\n        [1.0721, 5.9131]], grad_fn=<PowBackward0>)\nz: \n2.2685580253601074\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So then to perfom the gradients of z with respect x we must perfom z.backward() and check the result in x.grad, we know that the derivative with respect of x of z are x/2 so lets check if are the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"z.backward()\nprint(f\"gradients of z with respect x: \\n{x.grad}\")\nprint(f\"x/2: \\n{x/2}\")\n","execution_count":58,"outputs":[{"output_type":"stream","text":"gradients of z with respect x: \ntensor([[-0.6910,  0.2115],\n        [ 0.5177,  1.2158]])\nx/2: \ntensor([[-0.6910,  0.2115],\n        [ 0.5177,  1.2158]], grad_fn=<DivBackward0>)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Optimizers\n\nThen  we know that in this way we can calculate the gradients of the loss and then update our parameters.\nPytorch provides a set of optimizers that made this process automatically, such as stochastic gradient descent or adam."},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim\n\nOptimizer = optim.SGD(model.parameters(),lr=0.01)","execution_count":59,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then using this optimizer we can actually train our network:\nfirst we need two perfom a feedforward pass, calculate the loss with those values, then backpropagate to calculate our gradients (backward pass) and finally update our parameters(weights and biases)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get our data\nimages, labels = next(iter(dataloader))\n# Flatten images\nimages = images.view(images.shape[0], -1)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Optimizer.zero_grad()\noutput=model(images)\nloss=criterion(output,labels) #this is not reciprocable take care\nloss.backward()#we calculate the gradients of the loss with respect the parameters\nprint(f\"Weights before optimize(layer1): {model[0].weight}\")\nprint(f\"Example gradients(layer1): {model[0].weight.grad}\")","execution_count":61,"outputs":[{"output_type":"stream","text":"Weights before optimize(layer1): Parameter containing:\ntensor([[-2.3344e-02,  1.6693e-04,  2.6490e-02,  ..., -2.4348e-03,\n         -2.7917e-02, -6.7402e-03],\n        [ 1.3369e-02,  2.3005e-02, -1.6518e-02,  ..., -2.2352e-06,\n         -2.0824e-02, -4.7049e-03],\n        [-4.0413e-03,  3.4083e-02,  1.7977e-02,  ...,  1.3570e-02,\n         -2.8450e-02, -2.3205e-02],\n        ...,\n        [-2.0056e-02,  2.9529e-02, -3.5481e-02,  ..., -1.3736e-02,\n         -2.4008e-02,  3.5566e-02],\n        [ 1.2266e-03,  4.5396e-03, -2.4239e-02,  ..., -6.8462e-03,\n         -2.2042e-02,  1.7356e-02],\n        [ 3.3638e-03, -3.5051e-02, -4.7687e-03,  ..., -6.3527e-03,\n          2.5461e-02,  1.8548e-02]], requires_grad=True)\nExample gradients(layer1): tensor([[-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n        [-0.0023, -0.0023, -0.0023,  ..., -0.0023, -0.0023, -0.0023],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Then after calculate the loss and it's gradients we use our optimizer to update te parameters \nit's important to clean the gradients of the Optimizer cause they maybe acumulated (clean it before calulate the gradients of the loss) if you clean it here you will delete the new gradients"},{"metadata":{"trusted":true},"cell_type":"code","source":"Optimizer.step()\nprint(f\"Updated Weights after optimize(layer1): {model[0].weight}\")","execution_count":62,"outputs":[{"output_type":"stream","text":"Updated Weights after optimize(layer1): Parameter containing:\ntensor([[-2.3331e-02,  1.7935e-04,  2.6503e-02,  ..., -2.4224e-03,\n         -2.7905e-02, -6.7278e-03],\n        [ 1.3392e-02,  2.3028e-02, -1.6495e-02,  ...,  2.1082e-05,\n         -2.0801e-02, -4.6816e-03],\n        [-4.0413e-03,  3.4083e-02,  1.7977e-02,  ...,  1.3570e-02,\n         -2.8450e-02, -2.3205e-02],\n        ...,\n        [-2.0063e-02,  2.9523e-02, -3.5488e-02,  ..., -1.3742e-02,\n         -2.4014e-02,  3.5560e-02],\n        [ 1.2419e-03,  4.5549e-03, -2.4224e-02,  ..., -6.8309e-03,\n         -2.2027e-02,  1.7372e-02],\n        [ 3.3638e-03, -3.5051e-02, -4.7687e-03,  ..., -6.3527e-03,\n          2.5461e-02,  1.8548e-02]], requires_grad=True)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Ok now lets put all togheter below, first lets import our data,define our model, define our loss, create and optimizer and code the training loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import datasets,transforms\n\n\n\ntransform = transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5,), (0.5,)),\n                              ])\n# Download and load the data\ndata= datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\ndataloader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)\ndataloader.dataset.train_data.shape","execution_count":63,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n  warnings.warn(\"train_data has been renamed data\")\n","name":"stderr"},{"output_type":"execute_result","execution_count":63,"data":{"text/plain":"torch.Size([60000, 28, 28])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# TODO: Build a feed-forward network\nmodel = nn.Sequential(nn.Linear(784,250),\n                      nn.ReLU(),\n                      nn.Linear(250,120),\n                      nn.ReLU(),\n                      nn.Linear(120,10),\n                      nn.LogSoftmax(dim=1) \n                      #because we want to softmax by row (each row contains the score of a input), \n                      #we have 64 rows because our batch is of 64 samples\n                      )","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.NLLLoss()","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model,n_epochs,criterion):\n    Optimizer = optim.SGD(model.parameters(),lr=0.003)\n    for epoch in range(n_epochs):#epochs\n        epoch_loss=0\n        for images,labels in dataloader: #batches\n            Optimizer.zero_grad()\n            images=images.view(images.shape[0], -1)\n            predictions=model(images)\n            loss=criterion(predictions,labels)\n            loss.backward()\n            Optimizer.step()\n            epoch_loss+=loss.item()#we want just the number inside the tensor\n        print(f\"Epoch: {epoch} Training loss: {epoch_loss/len(dataloader)}\")        ","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model,5,criterion)","execution_count":67,"outputs":[{"output_type":"stream","text":"Epoch: 0 Training loss: 1.8970258088508394\nEpoch: 1 Training loss: 0.804226875336948\nEpoch: 2 Training loss: 0.4992022090184409\nEpoch: 3 Training loss: 0.4133524828628182\nEpoch: 4 Training loss: 0.3730686411960547\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_classify(img, ps, version=\"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == \"MNIST\":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == \"Fashion\":\n        ax2.set_yticklabels(['T-shirt/top',\n                            'Trouser',\n                            'Pullover',\n                            'Dress',\n                            'Coat',\n                            'Sandal',\n                            'Shirt',\n                            'Sneaker',\n                            'Bag',\n                            'Ankle Boot'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport helper\n\nimages, labels = next(iter(dataloader))\n\nimg = images[0].view(1, 784)\n# Turn off gradients to speed up this part\nwith torch.no_grad():\n    logps = model(img)\n\n# Output of the network are log-probabilities, need to take exponential for probabilities\nps = torch.exp(logps)\nview_classify(img.view(1, 28, 28), ps)","execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x648 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"So then let's move into a complex model, so we are trying to predict over 10 different classes of clothes where also there is more vaiance in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport helper\n\n# Define a transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,))])\n# Download and load the training data\ntrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\n# Download and load the test data\ntestset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)","execution_count":70,"outputs":[{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"26427392it [00:01, 13815520.21it/s]                             \n","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"32768it [00:00, 93220.41it/s]                            \n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"4423680it [00:01, 4050226.72it/s]                             \n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"8192it [00:00, 33508.26it/s]            ","name":"stderr"},{"output_type":"stream","text":"Extracting /tmp/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nfrom torch import optim\n\nclass fashionModel(torch.nn.Module):\n    def __init__(self,input_d):\n        super().__init__()\n        self.layer1=torch.nn.Linear(input_d,256)\n        self.nivel1Layer1 =torch.nn.Linear(256,80)\n        self.nivel1Layer2 =torch.nn.Linear(256,80)\n        self.Layer3=torch.nn.Linear(80+80,50)#we will concatenate the output of the 2 previous layers 200,200=400\n        self.Layer4=torch.nn.Linear(256+50,34)\n        self.outLayer=torch.nn.Linear(34,10)\n\n    \n    def forward(self,inputs):\n        h1=F.relu(self.layer1(inputs))\n        h2_1=F.relu(self.nivel1Layer1(h1))\n        h2_2=F.relu(self.nivel1Layer2(h1))\n        h3=F.relu(self.Layer3(torch.cat((h2_1,h2_2),dim=1)))\n        h4=F.relu(self.Layer4(torch.cat((h3,h1),dim=1)))\n        outputs=F.log_softmax(self.outLayer(h4),dim=1)\n        return outputs\n\n\n    def fit(self,batch_generator,num_epochs,criterion,Optimizer=None):\n        if not Optimizer:\n            Optimizer=optim.Adam(self.parameters(),lr=0.003)\n        train_samples=testloader.dataset.data.shape[0]\n        print(f\"{train_samples} training samples\")\n        for epoch in range(num_epochs):\n            epoch_loss=0\n            for images,labels in batch_generator:\n                Optimizer.zero_grad()#clean the gradients of the optimizer\n                outputs=self.forward(images.view(images.shape[0], -1))\n                loss=criterion(outputs,labels)#calculates the loss\n                loss.backward()#calculate the gradients of the loss with respect the model parameters\n                Optimizer.step()#we update the model parameters\n                epoch_loss+=loss.item()\n            print(f\"EPOCH:{epoch} loss:{epoch_loss}\")\n                ","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.zeros(20,784, requires_grad=False)\nprint(\"Test tensor: \",x.shape)\nmodel=fashionModel(784)\nout=model(x)\nprint(\"Test output:\",out.shape)\nprint(\"Check if output its ok (sum1):\\n\",torch.sum(torch.exp(out),dim=1))","execution_count":72,"outputs":[{"output_type":"stream","text":"Test tensor:  torch.Size([20, 784])\nTest output: torch.Size([20, 10])\nCheck if output its ok (sum1):\n tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000], grad_fn=<SumBackward2>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.NLLLoss()","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(trainloader,7,criterion)","execution_count":74,"outputs":[{"output_type":"stream","text":"10000 training samples\nEPOCH:0 loss:468.15620647370815\nEPOCH:1 loss:362.2424375638366\nEPOCH:2 loss:327.61986727267504\nEPOCH:3 loss:308.22981045395136\nEPOCH:4 loss:295.11384792625904\nEPOCH:5 loss:279.3860539570451\nEPOCH:6 loss:269.66879001259804\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport helper\n\n# Test out your network!\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.resize_(1, 784)\n\n# TODO: Calculate the class probabilities (softmax) for img\nps=torch.exp(model(img))\nprint(ps)\n# Plot the image and probabilities\nview_classify(img.resize_(1, 28, 28), ps, version='Fashion')","execution_count":78,"outputs":[{"output_type":"stream","text":"tensor([[6.4829e-05, 9.9960e-01, 1.1080e-05, 3.5222e-05, 2.1406e-05, 3.5954e-11,\n         2.6921e-04, 1.5254e-16, 1.1776e-07, 8.2611e-17]],\n       grad_fn=<ExpBackward>)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x648 with 2 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":370,"height":197},"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install hiddenlayer","execution_count":76,"outputs":[{"output_type":"stream","text":"Collecting hiddenlayer\n  Downloading https://files.pythonhosted.org/packages/b5/80/f284e0441945341c2fe669d70a17277746baf891fe4e517dcbe7784cbf24/hiddenlayer-0.2-py3-none-any.whl\nInstalling collected packages: hiddenlayer\nSuccessfully installed hiddenlayer-0.2\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import hiddenlayer as hl\nhl.build_graph(model, torch.zeros(1, 784))","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"<hiddenlayer.graph.Graph at 0x7f7a741bae10>","image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"346pt\" height=\"689pt\"\n viewBox=\"0.00 0.00 346.00 689.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 653)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-653 274,-653 274,36 -72,36\"/>\n<!-- fashionModel/outputs/19 -->\n<g id=\"node1\" class=\"node\"><title>fashionModel/outputs/19</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"111,-451 57,-451 57,-415 111,-415 111,-451\"/>\n<text text-anchor=\"start\" x=\"69\" y=\"-430\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n</g>\n<!-- 6231450612800329659 -->\n<g id=\"node8\" class=\"node\"><title>6231450612800329659</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"114,-368 42,-368 42,-332 114,-332 114,-368\"/>\n<text text-anchor=\"start\" x=\"50\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n</g>\n<!-- fashionModel/outputs/19&#45;&gt;6231450612800329659 -->\n<g id=\"edge7\" class=\"edge\"><title>fashionModel/outputs/19&#45;&gt;6231450612800329659</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M82.7276,-414.822C81.94,-404.19 80.9116,-390.306 80.0151,-378.204\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.4999,-377.867 79.2706,-368.153 76.519,-378.385 83.4999,-377.867\"/>\n<text text-anchor=\"middle\" x=\"94.5\" y=\"-389\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x160</text>\n</g>\n<!-- fashionModel/outputs/22 -->\n<g id=\"node2\" class=\"node\"><title>fashionModel/outputs/22</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"63,-285 9,-285 9,-249 63,-249 63,-285\"/>\n<text text-anchor=\"start\" x=\"21\" y=\"-264\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n</g>\n<!-- 17592418633936743618 -->\n<g id=\"node9\" class=\"node\"><title>17592418633936743618</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"72,-202 0,-202 0,-166 72,-166 72,-202\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-181\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n</g>\n<!-- fashionModel/outputs/22&#45;&gt;17592418633936743618 -->\n<g id=\"edge9\" class=\"edge\"><title>fashionModel/outputs/22&#45;&gt;17592418633936743618</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M36,-248.822C36,-238.19 36,-224.306 36,-212.204\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"39.5001,-212.153 36,-202.153 32.5001,-212.153 39.5001,-212.153\"/>\n<text text-anchor=\"middle\" x=\"49.5\" y=\"-223\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x306</text>\n</g>\n<!-- fashionModel/Linear[outLayer]/outputs/25 -->\n<g id=\"node3\" class=\"node\"><title>fashionModel/Linear[outLayer]/outputs/25</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"63,-119 9,-119 9,-83 63,-83 63,-119\"/>\n<text text-anchor=\"start\" x=\"23\" y=\"-98\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- fashionModel/outputs/26 -->\n<g id=\"node4\" class=\"node\"><title>fashionModel/outputs/26</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"69.5,-36 2.5,-36 2.5,-0 69.5,-0 69.5,-36\"/>\n<text text-anchor=\"start\" x=\"11\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LogSoftmax</text>\n</g>\n<!-- fashionModel/Linear[outLayer]/outputs/25&#45;&gt;fashionModel/outputs/26 -->\n<g id=\"edge1\" class=\"edge\"><title>fashionModel/Linear[outLayer]/outputs/25&#45;&gt;fashionModel/outputs/26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M36,-82.822C36,-72.1903 36,-58.306 36,-46.2035\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"39.5001,-46.1532 36,-36.1533 32.5001,-46.1533 39.5001,-46.1532\"/>\n<text text-anchor=\"middle\" x=\"47\" y=\"-57\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x10</text>\n</g>\n<!-- 3057211400019426499 -->\n<g id=\"node5\" class=\"node\"><title>3057211400019426499</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"112,-617 40,-617 40,-581 112,-581 112,-617\"/>\n<text text-anchor=\"start\" x=\"48\" y=\"-596\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n</g>\n<!-- 3057211400019426499&#45;&gt;fashionModel/outputs/22 -->\n<g id=\"edge2\" class=\"edge\"><title>3057211400019426499&#45;&gt;fashionModel/outputs/22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M51.0727,-580.78C33.1025,-566.143 12,-543.346 12,-517 12,-517 12,-517 12,-349 12,-330.351 17.9204,-310.246 23.8803,-294.731\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"27.2072,-295.841 27.7406,-285.26 20.725,-293.199 27.2072,-295.841\"/>\n<text text-anchor=\"middle\" x=\"25.5\" y=\"-430.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x256</text>\n</g>\n<!-- 17617636182696296312 -->\n<g id=\"node6\" class=\"node\"><title>17617636182696296312</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"112,-534 40,-534 40,-498 112,-498 112,-534\"/>\n<text text-anchor=\"start\" x=\"48\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n</g>\n<!-- 3057211400019426499&#45;&gt;17617636182696296312 -->\n<g id=\"edge3\" class=\"edge\"><title>3057211400019426499&#45;&gt;17617636182696296312</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M76,-580.822C76,-570.19 76,-556.306 76,-544.204\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.5001,-544.153 76,-534.153 72.5001,-544.153 79.5001,-544.153\"/>\n<text text-anchor=\"middle\" x=\"89.5\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x256</text>\n</g>\n<!-- 14326389785825915406 -->\n<g id=\"node7\" class=\"node\"><title>14326389785825915406</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"202,-534 130,-534 130,-498 202,-498 202,-534\"/>\n<text text-anchor=\"start\" x=\"138\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n</g>\n<!-- 3057211400019426499&#45;&gt;14326389785825915406 -->\n<g id=\"edge5\" class=\"edge\"><title>3057211400019426499&#45;&gt;14326389785825915406</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M95.0867,-580.822C107.974,-569.224 125.161,-553.755 139.388,-540.951\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"141.849,-543.444 146.941,-534.153 137.166,-538.241 141.849,-543.444\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x256</text>\n</g>\n<!-- 17617636182696296312&#45;&gt;fashionModel/outputs/19 -->\n<g id=\"edge4\" class=\"edge\"><title>17617636182696296312&#45;&gt;fashionModel/outputs/19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.6966,-497.822C78.7466,-487.19 80.1179,-473.306 81.3132,-461.204\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.8059,-461.449 82.3059,-451.153 77.8398,-460.761 84.8059,-461.449\"/>\n<text text-anchor=\"middle\" x=\"91\" y=\"-472\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x80</text>\n</g>\n<!-- 14326389785825915406&#45;&gt;fashionModel/outputs/19 -->\n<g id=\"edge6\" class=\"edge\"><title>14326389785825915406&#45;&gt;fashionModel/outputs/19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M148.61,-497.822C136.977,-486.331 121.498,-471.041 108.607,-458.307\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.939,-455.691 101.365,-451.153 106.02,-460.671 110.939,-455.691\"/>\n<text text-anchor=\"middle\" x=\"140\" y=\"-472\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x80</text>\n</g>\n<!-- 6231450612800329659&#45;&gt;fashionModel/outputs/22 -->\n<g id=\"edge8\" class=\"edge\"><title>6231450612800329659&#45;&gt;fashionModel/outputs/22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M69.0929,-331.822C63.4131,-320.868 55.943,-306.462 49.5377,-294.108\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.6047,-292.42 44.8943,-285.153 46.3904,-295.642 52.6047,-292.42\"/>\n<text text-anchor=\"middle\" x=\"70\" y=\"-306\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x50</text>\n</g>\n<!-- 17592418633936743618&#45;&gt;fashionModel/Linear[outLayer]/outputs/25 -->\n<g id=\"edge10\" class=\"edge\"><title>17592418633936743618&#45;&gt;fashionModel/Linear[outLayer]/outputs/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M36,-165.822C36,-155.19 36,-141.306 36,-129.204\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"39.5001,-129.153 36,-119.153 32.5001,-129.153 39.5001,-129.153\"/>\n<text text-anchor=\"middle\" x=\"47\" y=\"-140\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x34</text>\n</g>\n</g>\n</svg>\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Validation\nWe also have to validate our models using some matrics in order to know if is generalizing well or  if we have to implement some techniques to improve generalization such as dropout or L regularizations"},{"metadata":{},"cell_type":"markdown","source":"### Accuracy\nwe'll calculate the accuracy on our test set for our previous model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndataiter = iter(testloader)\nimages, labels = dataiter.next()","execution_count":79,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad(): #we don't need grads in the predictions so let's speed up this part\n    predictions=model(images.view(images.shape[0],-1))\n    predictions=torch.exp(predictions)","execution_count":95,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in order to get the predicted class since our predictions give us a probability for each class we can pickup the highest probability using the method .topk(n,dim) of our prediction tensors, this method returns a tuple (value,index) so for us will be (probability,class) "},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities,p_classes=predictions.topk(1,dim=1) #to pickup the top 1 of the row (since each row is a probability vector of the image)","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(p_classes.shape,\"\\n\",p_classes[:10])","execution_count":101,"outputs":[{"output_type":"stream","text":"torch.Size([64, 1]) \n tensor([[6],\n        [1],\n        [5],\n        [8],\n        [3],\n        [9],\n        [0],\n        [4],\n        [5],\n        [8]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels.shape)","execution_count":104,"outputs":[{"output_type":"stream","text":"torch.Size([64])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"then we want two know how many samples have been correctly classified so to perfom == operations p_classes and labels should have the same shapes so we can squeeze p_classes or unsqueeze labels (also view(*p_classes.shape)"},{"metadata":{"trusted":true},"cell_type":"code","source":"equals = p_classes.squeeze(1) == labels","execution_count":114,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the we just calculate the mean of corectly classified samples\nnote*: we cast the equals vector to a float vector in order to get a float division and not a integer division"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Accuracy: {torch.mean(equals.type(torch.FloatTensor)).item()*100}\")","execution_count":118,"outputs":[{"output_type":"stream","text":"Accuracy: 87.5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}